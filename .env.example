# Copy to .env and adjust as needed
POSTGRES_USER=rag
POSTGRES_PASSWORD=rag
POSTGRES_DB=rag

# Host connection string (matches docker-compose port mapping)
DATABASE_URL=postgres://rag:rag@localhost:5432/rag

# Optional logging configuration
RUST_LOG=info
# RAG_LOG_FORMAT=json   # uncomment for JSON logs to stderr (default is compact text)

# Output configuration (stdout presenters)
# RAG_OUTPUT_FORMAT can be: text | json | mcp (default: text)
# RAG_OUTPUT_FORMAT=json
# Pretty-print outputs (default: false)
# RAG_OUTPUT_PRETTY=true

# Optional: Hugging Face cache directory
# HF_HOME=/path/to/hf-cache

# Optional: disable ANSI colors in text output
# NO_COLOR=1

# OpenAI / LLM settings
# Set OPENAI_API_KEY when using OpenAI-hosted models.
# OPENAI_API_KEY=sk-...

# Override the default chat model (defaults to gpt-4o-mini if unset).
# OPENAI_MODEL=gpt-4o-mini

# Point to an alternative endpoint (e.g., Ollama's OpenAI-compatible bridge).
# Example for local Ollama: OPENAI_BASE_URL=http://localhost:11434/v1
# OPENAI_BASE_URL=https://api.openai.com/v1

# Default sampling parameters (can also be set via CLI flags).
# OPENAI_TEMPERATURE=0.2
# OPENAI_TOP_P=1.0

# HTTP client timeout in seconds for LLM calls.
# OPENAI_TIMEOUT_SECS=60
